\chapter{Contesto applicativo: il mondo della reportistica automatica}
\section{La reportistica aziendale automatizzata per favorire un modello decisionale data-driven}
Nel contesto dei \emph{financial services}, la capacità di organizzare i dati e tramutarli in insight strategici è centrale per ottimizzare i processi di enti ed imprese e garantirne il successo.
La digitalizzazione dei processi finanziari e l'evoluzione dell'ambito fintech promuovono un'elevata domanda di infrastrutture modernizzate per l'automazione dei processi interni. Da un lato, grazie all’adozione di tecnologie come RPA e machine learning, l’efficienza operativa delle aziende può aumentare di oltre il 40\%, riducendo drasticamente errori e tempi di esecuzione. Al contempo le autorità di vigilanza italiane (Banca d’Italia, CONSOB, IVASS) impongono un livello crescente di adempimenti normativi: gli intermediari devono produrre report periodici accurati, tempestivi e conformi ai formati ufficiali per il monitoraggio prudenziale.
In un mondo in cui i \emph{big data} permettono ai leader di enti e aziende di guidare strategicamente le operazioni in base non solo all'intuito, ma a dati statistici concreti e ben documentati e aggregati, diventa irrinunciabile l'adozione di sistemi che si occupino di elaborare tali dati per fornire documentazione ufficiale esaustiva rapidamente, nonché risaltare parametri rilevanti per scelte strategiche che impattano il business o la sicurezza dell'azienda.

La reportistica aziendale, tutt'altro che mera espressione di adempimento burocratico, costituisce una colonna portante dei processi decisionali, fungendo da linfa vitale per la business intelligence, il controllo di gestione e la digitalizzazione integrata dei flussi operativi.
Attraverso di essa, le organizzazioni non solo attestano la propria performance, ma costruiscono le fondamenta per una governance informata, agile e proattiva.
La produzione manuale dei report finanziari presenta tuttavia evidenti criticità. Richiede molte risorse di tempo e personale specializzato, espone a errori di trascrizione e incoerenze nei dati, e rende complessi aggiornamenti o riconfigurazioni rapide.
La soluzione evidente è dunque l'introduzione di un sistema di reportistica configurabile e avanzato che consenta alle realtà orientate ai dati di raccogliere e visualizzare indicatori chiave di performance, dati economico-finanziari, operativi e qualitativi, rendere trasparenti le metriche utili al confronto tra reparti o rispetto agli obiettivi strategici, e condividere informazioni in tempi rapidi, anche in mobilità, tramite interfacce dedicate e report compilati automaticamente nei formati più diffusi.
Un prodotto di questa natura, soprattutto se orientato alla facilità di configurazione e personalizzazione del servizio \footnotemark, consente un approccio computer-aided e data-driven al decision making, per una vasta gamma di utenti anche su piani gerarchici distinti: dagli operatori che necessitano di generare, scaricare e archiviare report sulle proprie attività, ricevendo avvisi tempestivi sull’esito delle elaborazioni; ai dirigenti e manager che impiegano dati aggregati e dashboard evolute per il controllo di gestione, l’analisi degli scostamenti e la pianificazione strategica; fino agli enti e alle aziende che intendono evolvere verso una gestione dei dati moderna, flessibile e basata sui dati, riducendo i tempi di produzione dei report e migliorando contestualmente la qualità delle decisioni.

\footnotetext{A tal fine, risulta imprescindibile segmentare le funzionalità per garantirne la modularità seguendo le esigenze di ciascun profilo utente, da quello operativo a quello dirigenziale. La scelta logica per ottenere questo risultato consiste nella progettazione di un'architettura basata su microservizi, di cui si discuterà in seguito.}

\section{Carenze nello stato dell'arte}

Esistono diverse soluzioni di mercato per la reportistica, ma ognuna presenta limiti in relazione a flessibilità e scalabilità. Ad esempio:
\begin{itemize}
    \item \textbf{ERP integrati} (come SAP o Oracle): offrono moduli dedicati al reporting, ma in genere sono sistemi piuttosto rigidi. Spesso richiedono personalizzazioni complesse per adattarsi a contesti specifici di business, rendendo onerosa la configurazione dei report rispetto alle esigenze variabili dell’azienda.
    \item \textbf{Strumenti di Business Intelligence commerciali} (Power BI, Tableau, Qlik): eccellono nella visualizzazione dei dati e nel data modeling, ma necessitano di infrastrutture complesse, competenze specifiche di progettazione report e spesso licenze software costose. Possono inoltre richiedere tempi
    lunghi di set-up per integrarsi con sistemi preesistenti.
    \item \textbf{Framework open-source di reporting e BI} (come Metabase, ReportServer, JasperReports): garantiscono maggiore flessibilità di personalizzazione e costi inferiori, ma impongono all’utente finale di possedere competenze tecniche elevate per installazione e integrazione. L’integrazione con sistemi legacy può risultare complicata e il supporto tecnico limitato.
\end{itemize}

Analizziamo nel complesso tali soluzioni con l'intenzione di approssimarne l'architettura software, evidenziandone le debolezze al fine di integrare le carenze individuate.
Anzitutto, la realizzazione di tali applicativi come sistema monolitico ostacola l’estensione funzionale e la scalabilità: qualunque modifica (ad esempio per un nuovo tipo di report) può richiedere di ridistribuire l’intero applicativo, e i carichi elevati devono essere bilanciati sull’intera piattaforma. Un approccio più flessibile è dato dalle architetture a microservizi, che scompongono le funzionalità in servizi indipendenti. In queste architetture ogni microservizio svolge un compito specifico e comunica con gli altri attraverso API ben definite. Ciò garantisce maggiore manutenibilità e resilienza: per esempio, se un componente è sottoposto a un picco di traffico (ad esempio il servizio di calcolo dei dati), solo quel servizio verrà replicato, anziché scalare l’intera applicazione. I microservizi favoriscono inoltre un deployment incrementale: si possono aggiornare singole funzionalità senza interrompere il servizio complessivo.
Del resto, questo non è un approccio che non sia già stato adottato: non è raro che i grandi player del settore fintech adottino sistemi a microservizi, poiché consentono di innovare rapidamente, isolare i malfunzionamenti e reagire agilmente ai picchi di traffico.

\emph{Metoda Finance S.R.L.}, azienda ospitante del tirocinio curriculare argomento di questa trattazione, sviluppa soluzioni software per la gestione documentale e la compliance normativa. In virtù del contesto di mercato accennato, l'azienda ha prodotto un motore interno di reportistica in grado di generare automaticamente file Excel e PDF, con configurazioni delle fonti dati semplificate a livello di funzione. Tuttavia, in assenza di un’interfaccia esterna accessibile, la versione originaria del sistema richiedeva che l’utente interagisse direttamente con il codice sorgente del motore di generazione. Tale condizione ne precludeva l’utilizzo da parte di operatori occasionali privi di competenze di programmazione o di una conoscenza, anche solo di base, dell’architettura e delle logiche di funzionamento del sistema. Da qui l’esigenza di avvolgere il servizio di reportistica in un'architettura facilmente fruibile, modulare e scalabile.

\section{Il progetto}
Nel panorama appena descritto si concretizza l'obiettivo del tirocinio curriculare oggetto di questa trattazione: l’ideazione e la prototipizzazione di un'architettura software modulare a microservizi, che esponga il sistema di generazione automatica di report, completo di storage dei documenti personali e sistema di autenticazione, rendendolo \emph{sicuro, scalabile, personalizzabile e facilmente integrabile} con tool di business intelligence o altri software gestionali preesistenti. Tenendo a mente i punti deboli dei prodotti disponibili sul mercato discussi in precedenza, il progetto di tirocinio si propone non come una semplice web application che esponga in rete il servizio di reportistica automatizzata, ma come un'architettura sicura e scalabile, che coniughi una user experience fluida e non influenzata dall'organizzazione sottostante, a una struttura modulare che fornisca performance elevate e facilità di manutenzione ed estensione.

Come verrà approfondito in un capitolo successivo, il progetto prevede l'implementazione di un'architettura a microservizi, isolati mediante l'impiego di container \emph{Docker} che garantiscono sia la scalabilità orizzontale sia la migrazione tra ambienti eterogenei.
Le funzionalità essenziali da implementare si concretizzano nell'utilizzo del motore di reportistica per realizzare un'interfaccia web, che sia accessibile sia mediante RESTful API, affinché il servizio sia agganciabile da altri applicativi per il settore dei financial services (e.g. tool di business intelligence quali PowerBI o Tableau), sia avvalendosi di un'interfaccia utente che renda immediati e intuitivi la generazione e la condivisione dei report, esportabili in formati diffusi quali Excel (.xlsm) e PDF.
Caratteristiche aggiuntive, come l'orchestrazione con \emph{\textbf{Docker Compose}}, l'arricchimento dell'interfaccia mediante \textbf{update real-time} dal server, l'implementazione di un sistema di \textbf{autenticazione} robusto e centralizzato, e l'utilizzo di un \textbf{gateway API} come intermediario tra client e microservizi completano il quadro di una soluzione moderna, scalabile e sicura.

Il framework adottato per la realizzazione dei servizi è \emph{Microsoft ASP.NET Core}, che consente di sviluppare applicazioni web e API in modo rapido ed efficiente, sfruttando le potenzialità del linguaggio C\# e dell'ecosistema \emph{.NET}.
Nello specifico, per la configurazione del container incaricato di esporre l'API RESTful si usufruisce del modello \textbf{ASP.NET Core Web API}, che rende agile e intuitiva la configurazione degli endpoint e la manutenzione della logica dell'API (documentazione dell'API esposta mediante il tool \textbf{Swagger}); l'applicativo web con interfaccia è stato realizzato secondo il modello \textbf{ASP.NET Core MVC}, utile per realizzare applicativi tradizionali\footnotemark, separando distintamente la logica di presentazione da quella di business, e facilitando lo sviluppo e la manutenzione dell'interfaccia utente. All'interfaccia utente sono poi aggiunte feature dinamiche mediante la tecnologia \textbf{SignlR}, che consente l'invio di notifiche asincrone mantenendo comunicazioni bidirezionali real-time tra client e server.
\footnotetext{
    Per "\emph{tradizionali}" si intende applicazioni multi-pagina (\emph{MPA}) con rendering server-side, una delle filosofie originarie per la realizzazione di applicazioni web. Nei capitoli successivi si argomenterà la scelta dell'utilizzo di tale modello rispetto a soluzioni meno mature, e.g. lo sviluppo di applicazioni singola-pagina (\emph{SPA}) con tecnologia \emph{Blazor}, sempre della kit di sviluppo \emph{ASP.NET}.
}

Per quanto concerne la struttura organizzativa dell'applicativo, annoveriamo altre feature che forniscono al progetto un'architettura del tutto simile un approccio a microservizi: la soluzione è basata su container indipendenti, orchestrati mediante \textbf{Docker Compose}; un container dedicato centralizza la gestione dell'autenticazione usufruendo di \textbf{Duende Identity Server}, \textbf{EntityFramework Core} e \textbf{ASP.NET Core Identity e Authentication} (esponendo servizi OpenID Connect per il browser e JWT per le API). L'adozione di un gateway API per un reverse proxying potente e facilmente configurabile con \textbf{YARP}, per la gestione delle richieste e l'applicazione di policy di sicurezza, garantendo non solo modularità e manutenibilità evolute nel tempo, ma una navigazione fluida tra i vari servizi, eliminando la necessità di autenticazioni multiple nell'accedere a funzionalità distinte del sistema, la cui separazione interna non dovrebbe influire sull'esperienza dell'utente.

In definitiva, la soluzione proposta non solo è tecnicamente adeguata ai requisiti richiesti da organizzazioni data-intensive, ma si collocherebbe con piena efficacia in scenari reali, promuovendo usabilità, integrabilità ed evolvibilità. Essa incarna il passaggio dalla reportistica statica e reattiva a un ecosistema dinamico, interconnesso e capace di generare valore continuo, trasformando i dati nel più prezioso alleato per il governo dell’impresa.

\section{Struttura della tesi}
Il seguito della trattazione si articolerà nelle sezioni seguenti:

\begin{enumerate}
	\item \textbf{Accenni alle architetture distribuite orientate ai microservizi} e descrizione di concetti e principi propri degli applicativi \textbf{software web-based} impiegati contestualmente alla soluzione prodotta.
	\item \textbf{Panoramica sugli strumenti tecnologici} impiegati, con particolare riferimento al kit \emph{ASP.NET Core}, framework centrale per la realizzazione della soluzione in esame.
	\item \textbf{Analisi del progetto}, con illustrazione della struttura progettuale, delle scelte implementative e delle prospettive di evoluzione verso scenari di deployment distribuito e multicanale.
	\item \textbf{Considerazioni finali} sull'esperienza di tirocinio e sviluppi futuri per il progetto.
\end{enumerate}